{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479fda00-4446-42bb-b063-0e68f361270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import pdfplumber\n",
    "from API-YoungsModulus import call_deepseek_llm\n",
    "from contains_keywords-youngs import contains_keywords\n",
    "from Clean import ParagraphParser  # ç”¨è¿™ä¸ªè¿‡æ»¤\n",
    "\n",
    "# è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„\n",
    "input_folder = r\"Your_split_pdfs_Path\"\n",
    "processed_folder = os.path.join(input_folder, \"processed_pdfs\")     # å·²å¤„ç†æˆåŠŸçš„\n",
    "wasted_pdfs = os.path.join(input_folder, \"wasted_pdfs\")         # ä»€ä¹ˆéƒ½æ²¡æœ‰çš„æ–‡çŒ®\n",
    "os.makedirs(processed_folder, exist_ok=True)\n",
    "os.makedirs(wasted_pdfs, exist_ok=True)\n",
    "\n",
    "# å…³é”®è¯å­—å…¸ï¼ˆèšåˆç‰© ä»¥åŠ åŠ›å­¦æ€§èƒ½ï¼‰\n",
    "keyword_dict = {\n",
    "    \"Polymers\": [\n",
    "        # é€šç”¨èšåˆç‰©åŠå…±èšç‰©\n",
    "        \"polymer\", \"copolymer\", \"blend\", \"biopolymer\",\n",
    "        # å¸¸è§å•†ç”¨æˆ–åˆæˆèšåˆç‰©\n",
    "        \"PLA\", \"polylactic acid\", \"PCL\", \"polycaprolactone\",\n",
    "        \"PET\", \"polyethylene terephthalate\", \"PMMA\", \"polymethyl methacrylate\",\n",
    "        \"PU\", \"polyurethane\", \"PA\", \"polyamide\", \"nylon\",\n",
    "        \"PVC\", \"polyvinyl chloride\", \"PVA\", \"polyvinyl alcohol\",\n",
    "        \"PAN\", \"polyacrylonitrile\", \"PVP\", \"polyvinylpyrrolidone\",\n",
    "        \"PDMS\", \"polydimethylsiloxane\", \"PC\", \"polycarbonate\",\n",
    "        \"PBS\", \"polybutylene succinate\", \"PGA\", \"poly(Î³-glutamic acid)\",\n",
    "        \"PE\", \"polyethylene\", \"PP\", \"polypropylene\", \"polyester\",\n",
    "        # ç”Ÿç‰©åŸº/å¤©ç„¶èšåˆç‰©\n",
    "        \"GelMA\", \"gelatin methacrylate\", \"gelatin\", \"collagen\",\n",
    "        \"chitosan\", \"alginate\", \"sodium alginate\", \"cellulose\",\n",
    "        \"nanocellulose\", \"pectin\", \"lignin\", \"starch\", \"hyaluronic acid\",\n",
    "        \"silk fibroin\", \"polyethylene glycol\", \"polydopamine\",\n",
    "        \"polyacrylamide\"\n",
    "    ],\n",
    "    \"Additives or Modifiers\": [\n",
    "        # åŸºç¡€åŠŸèƒ½æ·»åŠ å‰‚\n",
    "        \"additive\", \"modifier\", \"plasticizer\", \"compatibilizer\", \"filler\", \"blend\",\n",
    "        \"hybrid\", \"nanocomposite\", \"composite\",\n",
    "        # æ— æœºçº³ç±³ææ–™\n",
    "        \"nanoparticle\", \"nanofiller\", \"nanoclay\", \"TiO2\", \"SiO2\", \"ZnO\", \"CaCO3\",\n",
    "        \"clay\", \"montmorillonite\", \"halloysite\", \"bentonite\",\n",
    "        # æœ‰æœº/é«˜åˆ†å­å…±æ··ç‰©\n",
    "        \"PBAT\", \"PEG\", \"PHA\", \"PBSA\", \"PPC\", \"EVA\", \"PLA-g-MA\",\n",
    "        # ç”Ÿç‰©åŸº/å¤©ç„¶ææ–™\n",
    "        \"cellulose nanocrystal\", \"microcrystalline cellulose\", \"hemicellulose\",\n",
    "        \"soy protein\", \"wheat bran\", \"rice husk\",\n",
    "        # ç¢³åŸºææ–™\n",
    "        \"CNT\", \"carbon nanotube\", \"carbon black\", \"graphene\", \"graphene oxide\",\n",
    "        \"reduced graphene oxide\",\n",
    "        # çº¤ç»´åŠå¢å¼ºææ–™\n",
    "        \"fiber\", \"natural fiber\", \"glass fiber\", \"bamboo fiber\", \"hemp fiber\",\n",
    "        \"basalt fiber\", \"jute fiber\", \"kenaf fiber\",\n",
    "        # å¢å¡‘å‰‚\n",
    "        \"glycerol\", \"triacetin\", \"citrate\", \"ATBC\", \"TEC\", \"tributyl citrate\",\n",
    "        \"polyethylene glycol\",\n",
    "        # å…±æ··åŠç›¸å®¹åŒ–\n",
    "        \"blending\", \"blended\", \"copolymerized\", \"reactive compatibilization\",\n",
    "        \"immiscible\", \"miscible\",\n",
    "        # å…¶ä»–æ·»åŠ å‰‚\n",
    "        \"antioxidant\", \"nucleating agent\", \"chain extender\", \"crosslinker\",\n",
    "        \"UV stabilizer\", \"thermal stabilizer\", \"fire retardant\", \"flame retardant\"\n",
    "    ],\n",
    "    \"mechanical properties\":\n",
    "    [\n",
    "    \"tensile strength\", \"breaking strength\", \"tensile properties\",\n",
    "    \"elongation at break\", \"breaking elongation\",\n",
    "    \"young's modulus\", \"tensile modulus\",\n",
    "    \"flexural modulus\", \"bending modulus\", \"flexural stiffness\",\n",
    "    \"impact strength\", \"impact toughness\",\n",
    "    \"stress-strain\", \"mechanical behavior\",\n",
    "    \"hardness\", \"shore hardness\", \"rockwell\", \"durometer\",\n",
    "    ],\n",
    "    \"Glass Transition\": [\"glass transition\", \"Tg\"],\n",
    "    \"Melting Point\": [\"melting point\", \"melting temperature\", \"Tm\"]\n",
    "    \n",
    "}\n",
    "def extract_pdf_with_layout(pdf_path):\n",
    "    \"\"\"æå–æ–‡æœ¬ï¼Œä¸æè¡¨æ ¼ï¼Œé¿å… Ascii85 é”™è¯¯\"\"\"\n",
    "    full_text = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            try:\n",
    "                text = page.extract_text() or \"\"\n",
    "                full_text.append(f\"\\n=== Page {page.page_number} ===\\n{text}\")\n",
    "            except Exception as e:\n",
    "                full_text.append(f\"\\nâš ï¸ ç¬¬ {page.page_number} é¡µæå–å¤±è´¥ï¼š{e}\")\n",
    "    return \"\\n\".join(full_text)\n",
    "\n",
    "\n",
    "def process_pdf(pdf_path):\n",
    "    filename = os.path.basename(pdf_path)\n",
    "    out_dir = os.path.join(os.path.dirname(pdf_path), \"extracted_output\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    txt_path = os.path.join(out_dir, filename.replace(\".pdf\", \".txt\"))\n",
    "\n",
    "    if os.path.exists(txt_path):\n",
    "        print(f\"â© å·²å¤„ç†è¿‡ï¼Œè·³è¿‡ï¼š{filename}\")\n",
    "        shutil.move(pdf_path, os.path.join(processed_folder, filename))\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        raw = extract_pdf_with_layout(pdf_path)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {filename} æå–å¤±è´¥ï¼š{e}\")\n",
    "        return\n",
    "\n",
    "    parser = ParagraphParser(name=filename, debug=False)\n",
    "    parser.parse(raw)\n",
    "    if not parser.is_valid():\n",
    "        return\n",
    "    text = parser.text.strip()\n",
    "\n",
    "    # Step 1: åˆ¤æ–­æ˜¯å¦å« \"èšåˆç‰©\"\n",
    "    found_polymers, _, matched_polymer_words = contains_keywords(text, {\"Polymers\": keyword_dict[\"Polymers\"]})\n",
    "    if not found_polymers:\n",
    "        print(f\"â© è·¯å¾„ä¸º {pdf_path} çš„ {filename} ä¸å« Polymers å…³é”®è¯ï¼Œç§»åŠ¨åˆ° wasted_pdfs\")\n",
    "        shutil.move(pdf_path, os.path.join(wasted_pdfs, filename))\n",
    "        return\n",
    "    else:\n",
    "        print(f\"ğŸ“Œ è·¯å¾„ä¸º {pdf_path} çš„ {filename} å‘½ä¸­ Polymers å…³é”®è¯ï¼š{', '.join(matched_polymer_words.get('Polymers', []))}\")\n",
    "\n",
    "    # Step 2: åˆ¤æ–­æ˜¯å¦åŒ…å«åŠ›å­¦æ€§èƒ½å…³é”®è¯\n",
    "    mech_dict = {\"mechanical properties\": keyword_dict[\"mechanical properties\"]}\n",
    "    found_mech, matched_categories, matched_words = contains_keywords(text, mech_dict)\n",
    "    if not found_mech:\n",
    "        print(f\"â© è·¯å¾„ä¸º {pdf_path} çš„ {filename} è™½å« Polymers å…³é”®è¯ï¼Œä½†æœªæ£€æµ‹åˆ°ä»»ä½• åŠ›å­¦æ€§èƒ½ å…³é”®è¯ï¼Œç§»åŠ¨åˆ° wasted_pdfs\")\n",
    "        shutil.move(pdf_path, os.path.join(wasted_pdfs, filename))\n",
    "        return\n",
    "    else:\n",
    "        print(f\"ğŸ“ˆ è·¯å¾„ä¸º {pdf_path} çš„ {filename} å‘½ä¸­ åŠ›å­¦æ€§èƒ½ å…³é”®è¯ï¼š{', '.join(matched_words.get('mechanical properties', []))}\")\n",
    "\n",
    "    for cat, words in matched_words.items():\n",
    "        print(f\"    - {cat}ï¼š{', '.join(words)}\")\n",
    "\n",
    "    prompt = f\"ğŸ“ƒ ç›¸å…³å‚æ•°çš„æ–‡æœ¬å¦‚ä¸‹ï¼š\\n{text}\"\n",
    "    try:\n",
    "        ans = call_deepseek_llm(prompt)\n",
    "        if not ans or not ans.strip():\n",
    "            print(f\"âš ï¸ è·¯å¾„ä¸º {pdf_path} çš„ {filename} æ— APIå“åº”ï¼Œè·³è¿‡\")\n",
    "            return\n",
    "        content = f\"ğŸ§¾ æå–ç»“æœï¼š\\n{ans.strip()}\\n\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è·¯å¾„ä¸º {pdf_path} çš„ {filename} å¤„ç†å‡ºé”™ï¼š{e}\")\n",
    "        return\n",
    "\n",
    "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    shutil.move(pdf_path, os.path.join(processed_folder, filename))\n",
    "    print(f\"âœ… æå–å®Œæˆï¼š{filename}\")\n",
    "    print(f\"ğŸ“‚ åŸè·¯å¾„ï¼š{pdf_path}\")\n",
    "    print(f\"ğŸ“„ å†™å…¥è·¯å¾„ï¼š{txt_path}\")\n",
    "\n",
    "\n",
    "# éå†å¤„ç†æ‰€æœ‰ PDFï¼ˆæ–¹æ³•ä¸€ï¼šè¿‡æ»¤å­ç›®å½•ï¼‰\n",
    "for root, dirs, files in os.walk(input_folder):\n",
    "    # è¿‡æ»¤ä¸éœ€é€’å½’çš„å­ç›®å½•\n",
    "    dirs[:] = [d for d in dirs if d not in (\n",
    "        os.path.basename(processed_folder),\n",
    "        os.path.basename(wasted_pdfs),\n",
    "        'extracted_output'\n",
    "    )]\n",
    "    for fn in files:\n",
    "        if fn.lower().endswith('.pdf') and not fn.startswith('._'):\n",
    "            process_pdf(os.path.join(root, fn))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (unstruct)",
   "language": "python",
   "name": "unstruct"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
